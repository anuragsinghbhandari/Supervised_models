{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIpW5IpILJRy"
      },
      "source": [
        "# Lasso (Least Absolute Shrinkage and Selection Operator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lDnhd8ALwmI"
      },
      "source": [
        "It uses **L1 Regularization** to avoid overfitting.  \n",
        "*Regularization is used to reduce overfitting the model by adding a penalty term (lambda) to the model*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMuCy7zYP_5B"
      },
      "source": [
        "The penalty term reduces the value of coefficients or eliminate few coefficients , as a result overfitting can be avoided.\n",
        "\n",
        "***This process is called shrinkage.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WDAnCDUWbm1"
      },
      "source": [
        "## Same as Linear Regression, only difference is the adding of l1 regularization in the cost function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wgYLViWWok8"
      },
      "source": [
        "$ J = MSE + L1 $   \n",
        "\n",
        "$ J = \\dfrac{1}{n} (\\sum_{i=1}^{n} (y_i-\\hat{y}_i)^2 ) + \\lambda\\sum_{j=1}^{m}|w_j| $  \n",
        "  \n",
        "For $ w_j >0 $  \n",
        "$ dJ_w = \\dfrac{- 2}{n} (\\sum_{i=1}^{n} x_j(y_i-\\hat{y}_i) )+\\lambda$    \n",
        "  \n",
        "$ dJ_b = \\dfrac{ - 2}{n} (\\sum_{i=1}^{n} (y_i-\\hat{y}_i)) $  \n",
        "  \n",
        "For $ w_j < 0 $  \n",
        "$ dJ_w = \\dfrac{- 2}{n} (\\sum_{i=1}^{n} x_j(y_i-\\hat{y}_i) )-\\lambda$    \n",
        "  \n",
        "$ dJ_b = \\dfrac{ - 2}{n} (\\sum_{i=1}^{n} (y_i-\\hat{y}_i)) $  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gc1PVijoXuaq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Lasso:\n",
        "  def __init__(self, learning_rate: float, no_of_iteration: float, lambda_param: float):\n",
        "    self.lr = learning_rate\n",
        "    self.iter = no_of_iteration\n",
        "    self.lmbd = lambda_param\n",
        "\n",
        "  def fit(self, X_train, Y_train):\n",
        "    self.rows, self.columns = X_train.shape\n",
        "    self.w = np.zeros(self.columns)\n",
        "    self.b = 0\n",
        "    self.X = X_train\n",
        "    self.Y = Y_train\n",
        "    for _ in range(self.iter):\n",
        "      self.update_weights()\n",
        "\n",
        "  def update_weights(self):\n",
        "    y_pred = self.predict(self.X)\n",
        "    dw = (-2/self.rows)*((self.X.T).dot(self.Y-y_pred))+np.sign(self.w)*self.lmbd\n",
        "    db = (-2/self.rows)*(np.sum((self.Y-y_pred)))\n",
        "    self.w -= self.lr*dw\n",
        "    self.b -= self.lr*db\n",
        "\n",
        "  def predict(self, X_test):\n",
        "    return X_test.dot(self.w)+self.b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"D:/Ml/part1/data/diabetes.csv\")\n",
        "X = df.drop(columns=[\"Outcome\"]).values\n",
        "Y = df['Outcome'].values\n",
        "type(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=0.2, random_state=42)\n",
        "model = Lasso(0.0005,1000, 0.01)\n",
        "model.fit(X_train=X_train, Y_train=Y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
              "       0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0])"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#calculating predicted values\n",
        "Y_pred = model.predict(X_test=X_test)\n",
        "#actual answers\n",
        "Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.22888763,  0.11308148,  0.053963  ,  0.17617352,  0.33551271,\n",
              "        0.32735342, -0.16140876,  0.27310792,  0.34274217,  0.46117543,\n",
              "        0.20195508,  0.57221695,  0.27662843,  0.25007352,  0.0205198 ,\n",
              "        0.24498773,  0.08046485,  0.03726933,  0.39747742,  0.30645647,\n",
              "        0.17622132,  0.04386817,  0.32675447,  0.04098868,  0.36130902,\n",
              "        0.53160223,  0.07620954, -0.05668936,  0.18447834,  0.11220508,\n",
              "        0.51680298,  0.52907177,  0.47917983,  0.36465273,  0.3839261 ,\n",
              "        0.44814079,  0.63766892,  0.19422029,  0.36148618,  0.26822083,\n",
              "        0.0131656 ,  0.34074157,  0.35308191,  0.26213377, -0.0307818 ,\n",
              "        0.36195263,  0.43192572,  0.14963292,  0.29516517,  0.69380324,\n",
              "       -0.03409085,  0.46764848,  0.57633461,  0.17298972,  0.08141239,\n",
              "       -0.0436438 ,  0.45390681, -0.31741603,  0.25973892,  0.41027607,\n",
              "        0.43191792,  0.20466589,  0.30532798,  0.26225237,  0.04096316,\n",
              "        0.31892759, -0.04127728,  0.43683674, -0.03165653,  0.5025373 ,\n",
              "        0.4632526 ,  0.04471601,  0.17817251,  0.07268728,  0.06109338,\n",
              "        0.36201319,  0.15740634,  0.12644942,  0.11322681,  0.18932575,\n",
              "        0.37397129,  0.08625558,  0.00400983,  0.26574743,  0.17815431,\n",
              "        0.50544506,  0.52826942,  0.25121026,  0.09027389,  0.01961679,\n",
              "        0.00476829,  0.16801163, -0.3556158 ,  0.23428757,  0.2815395 ,\n",
              "        0.34391876,  0.24013213,  0.08164615,  0.43121988,  0.07063682,\n",
              "        0.41848771,  0.01014705,  0.48429841,  0.32495049,  0.37748416,\n",
              "        0.19022291,  0.19299883,  0.4569795 ,  0.13007801,  0.34571027,\n",
              "        0.04101442,  0.23869961, -0.16589378,  0.5075273 ,  0.1554612 ,\n",
              "        0.18036857,  0.3767969 ,  0.15726087, -0.00203451,  0.24033743,\n",
              "       -0.02528568,  0.18555544,  0.19400356,  0.04843283,  0.16032805,\n",
              "        0.33846665, -0.075506  ,  0.59472335,  0.57329132,  0.46286023,\n",
              "        0.41094384,  0.56327735,  0.08010016,  0.33753066,  0.51490628,\n",
              "        0.07791579,  0.14860089,  0.56765456,  0.50649587, -0.17067272,\n",
              "        0.0410805 , -0.0574564 ,  0.15377496,  0.31433561,  0.05034217,\n",
              "        0.21007038,  0.13221389, -0.14638451,  0.25519375,  0.46825797,\n",
              "        0.07279012,  0.32170303,  0.24111364,  0.17183257])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.348098161459329)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mean_absolute_error = np.sum(abs(Y_pred-Y_test))/len(Y_test)\n",
        "mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.18782317918350735)"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mean_squared_error = np.sum((Y_pred-Y_test)**2)/len(Y_test)\n",
        "mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
